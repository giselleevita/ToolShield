%% ToolShield Bachelor Thesis — TU Darmstadt Corporate Design
%% Based on DEMO-TUDaThesis.tex (tuda-ci v4.05, 2025-11-13)

% ── PDF/A-2b compliance (must precede \documentclass) ────────────────────────
\DocumentMetadata{
  pdfstandard=a-2b,
  pdfversion=1.7,
  lang=en,
}

\documentclass[
  english,
  accentcolor=9c,
  ruledheaders=section,
  class=report,
  thesis={type=bachelor},
  fontsize=11pt,
  parskip=half-,
  custommargins=true,
  marginpar=false,
  accept-missing-logos=true, % Place tuda_logo.pdf in thesis/ and remove this option once the official logo file is in place.
]{tudapub}

% ── Packages ─────────────────────────────────────────────────────────────────
\usepackage[english]{babel}
\usepackage{microtype}
\usepackage[autostyle]{csquotes}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\graphicspath{{figures/}}
\usepackage{pdfpages} % for including signed declaration scan
\usepackage{booktabs}
\usepackage{verbatim}

% ── Bibliography (biblatex, as required by TUDa-CI) ─────────────────────────
\usepackage{biblatex}
\addbibresource{references.bib}

% ── PDF metadata ─────────────────────────────────────────────────────────────
\hypersetup{
  pdfauthor={Giselle Evita},
  pdfkeywords={prompt injection, LLM, tool-use, truncation, security, TU Darmstadt},
}

% ── Submission metadata macros (fill before submission) ─────────────────────
\newcommand{\SupervisorName}{(to be filled)}
\newcommand{\SecondReviewerName}{(to be filled)}
\newcommand{\SubmissionDate}{(to be filled)}
\newcommand{\ExamDate}{(to be filled)}

% ── Thesis metadata ──────────────────────────────────────────────────────────
\title{ToolShield: Prompt Injection Detection for Tool-Using LLM Agents}
\author{Giselle Evita}
\reviewer{\SupervisorName \and \SecondReviewerName}
\department{inf}
\institute{Department of Computer Science}
%\group{[Research Group to be filled]}  % only used for doctoral theses
\submissiondate{\SubmissionDate}
\examdate{\ExamDate}

% ── Document ─────────────────────────────────────────────────────────────────
\begin{document}

\maketitle

% ── Declaration (Eigenständigkeitserklärung) ─────────────────────────────────
% According to TU Darmstadt APB §22(7), a signed declaration must be included.
% Replace with signed declaration PDF before submission.
% \includepdf[pages=-]{signed_declaration.pdf}
\IfFileExists{signed_declaration.pdf}{%
  \includepdf[pages=-]{signed_declaration.pdf}%
}{%
  \newpage
  \thispagestyle{empty}
  \begin{center}
  {\large Replace with signed declaration PDF: \texttt{signed\_declaration.pdf}.}
  \end{center}
}

% ── Abstract ─────────────────────────────────────────────────────────────────
\newpage
\begin{abstract}
This thesis addresses the problem of detecting prompt injection attacks in tool-using LLM systems, where user-provided prompts are combined with privileged tool context and forwarded to a language model for tool invocation. A prompt injection detection pipeline called ToolShield is presented, evaluating multiple baseline models (heuristics, TF-IDF, transformer classifiers) and context-augmented transformer detectors across controlled split protocols. The central finding is that naive right-truncation of context-augmented inputs can silently remove the user prompt under production-scale tool schemas in a controlled synthetic benchmark, causing detection performance to collapse to near-random levels. A prompt-preserving truncation strategy is proposed that reserves a minimum token budget for the user prompt, maintaining high detection performance under the evaluated long-schema conditions. All experiments are reproducible via deterministic seeds, automated verification scripts, and a public artifact bundle.
\end{abstract}

\tableofcontents

% ── Chapters ─────────────────────────────────────────────────────────────────
\input{chapters/introduction}
\input{chapters/related_work}
\input{chapters/methodology}
\input{chapters/implementation}
\input{chapters/results}
\input{chapters/discussion}
\input{chapters/threats_to_validity}
\input{chapters/conclusion}

% ── Appendix ─────────────────────────────────────────────────────────────────
\appendix

\chapter{Experimental Tables and Figures}
\label{sec:tables_and_figures}
\input{chapters/tables}

\chapter{Reproducibility Notes}
\label{sec:reproducibility_notes}

All experimental results reported in this thesis can be reproduced from the
repository using two commands:

\begin{verbatim}
make compare_truncation_longschema
make verify_longschema_results
\end{verbatim}

The first command executes the full long-schema truncation ablation pipeline
(dataset generation, splitting, training, evaluation, and aggregation). The
second command runs the automated verification script, which checks artifact
completeness, truncation invariant consistency, and ROC-AUC regression bounds.

\paragraph{Artifact index.}
The file \texttt{THESIS\_ARTIFACTS.md} in the repository root serves as the
authoritative index linking each thesis table and figure to the exact data
file from which it was derived.

\paragraph{Supporting artifacts.}
The following files document the experimental environment and execution:

\begin{itemize}
    \item \texttt{run\_manifest.md} --- records the git commit hash, executed
          commands, dataset configuration, and model settings for each
          experiment run.
    \item \texttt{environment\_freeze.txt} --- captures the exact Python
          package versions (torch, transformers, scikit-learn, etc.) used
          during training and evaluation.
    \item \texttt{verification\_output.txt} --- contains the full output of
          the automated verification pipeline, confirming that all artifact
          checks passed.
\end{itemize}

Together with deterministic seeds and controlled split protocols, these
artifacts ensure that reported results are traceable to a specific repository
state and reproducible under equivalent conditions.

% ── Bibliography ─────────────────────────────────────────────────────────────
\printbibliography

\end{document}
